{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    sys.path.insert(0, '../../')\n",
    "sys.path.insert(0, '../../')\n",
    "from src.data.preprocessing import *\n",
    "from src.data.load_data_yoochoose import *\n",
    "from src.models.model import LSTMRec\n",
    "from src.models import train\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import Precision, Recall\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(train_x, train_y, test_x, test_y, hparams):\n",
    "    unique_items = len(train_y[0])\n",
    "    model = LSTMRec(\n",
    "        vocabulary_size=unique_items,\n",
    "        emb_output_dim=hparams['emb_dim'],\n",
    "        lstm_units=hparams['lstm_units'],\n",
    "        lstm_activation=hparams['lstm_activation'],\n",
    "        lstm_recurrent_activation=hparams['lstm_recurrent_activation'],\n",
    "        lstm_dropout=hparams['lstm_dropout'],\n",
    "        lstm_recurrent_dropout=hparams['lstm_recurrent_dropout'],\n",
    "        dense_activation=hparams['dense_activation']\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=hparams['learning_rate'],\n",
    "            beta_1=hparams['adam_beta_1'],\n",
    "            beta_2=hparams['adam_beta_2'],\n",
    "            epsilon=hparams['adam_epsilon']\n",
    "        ),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            Precision(top_k=1, name='P_at_1'),\n",
    "            Precision(top_k=3, name='P_at_3'),\n",
    "            Precision(top_k=5, name='P_at_5'),\n",
    "            Precision(top_k=10, name='P_at_10'),\n",
    "            Recall(top_k=10, name='R_at_10'),\n",
    "            Recall(top_k=50, name='R_at_50'),\n",
    "            Recall(top_k=100, name='R_at_100')\n",
    "        ]\n",
    "    )\n",
    "    hst = model.fit(\n",
    "        x=train_x,\n",
    "        y=train_y,\n",
    "        batch_size=hparams['batch_size'],\n",
    "        epochs=3,\n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                monitor='val_R_at_10',\n",
    "                patience=10,\n",
    "                mode='max',\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                filepath='../../models/' + hparams['run_id'] + '.ckpt',\n",
    "                monitor='val_R_at_10',\n",
    "                mode='max',\n",
    "                save_best_only=True,\n",
    "                save_weights_only=True\n",
    "            ),\n",
    "            TensorBoard(\n",
    "                log_dir='../../logs/' + hparams['run_id'],\n",
    "                histogram_freq=1\n",
    "            )\n",
    "        ],\n",
    "        validation_split=0.2\n",
    "    )\n",
    "\n",
    "    val_best_epoch = np.argmax(hst.history['val_R_at_10'])\n",
    "    test_results = model.evaluate(test_x, test_y)\n",
    "    with tf.summary.create_file_writer('../../logs/' + hparams['run_id']).as_default():\n",
    "        hp.hparams(hparams)\n",
    "        tf.summary.scalar('train.final_loss', hst.history[\"val_loss\"][val_best_epoch], step=0)\n",
    "        tf.summary.scalar('train.final_P_at_1', hst.history[\"val_P_at_1\"][val_best_epoch], step=0)\n",
    "        tf.summary.scalar('train.final_P_at_3', hst.history[\"val_P_at_3\"][val_best_epoch], step=0)\n",
    "        tf.summary.scalar('train.final_P_at_5', hst.history[\"val_P_at_5\"][val_best_epoch], step=0)\n",
    "        tf.summary.scalar('train.final_P_at_10', hst.history[\"val_P_at_10\"][val_best_epoch], step=0)\n",
    "        tf.summary.scalar('train.final_R_at_10', hst.history[\"val_R_at_10\"][val_best_epoch], step=0)\n",
    "        tf.summary.scalar('train.final_R_at_50', hst.history[\"val_R_at_50\"][val_best_epoch], step=0)\n",
    "        tf.summary.scalar('train.final_R_at_100', hst.history[\"val_R_at_100\"][val_best_epoch], step=0)\n",
    "\n",
    "        tf.summary.scalar('train.final_loss', test_results[0], step=0)\n",
    "        tf.summary.scalar('train.final_P_at_1', test_results[1], step=0)\n",
    "        tf.summary.scalar('train.final_P_at_3', test_results[2], step=0)\n",
    "        tf.summary.scalar('train.final_P_at_5', test_results[3], step=0)\n",
    "        tf.summary.scalar('train.final_P_at_10', test_results[4], step=0)\n",
    "        tf.summary.scalar('train.final_R_at_10', test_results[5], step=0)\n",
    "        tf.summary.scalar('train.final_R_at_50', test_results[6], step=0)\n",
    "        tf.summary.scalar('train.final_R_at_100', test_results[7], step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {}\n",
    "hparams['emb_dim'] = 50 * np.random.randint(1, 11)\n",
    "hparams['lstm_units'] = 25 * np.random.randint(1, 13)\n",
    "hparams['lstm_activation'] = ['relu', 'sigmoid', 'tanh', 'linear', 'softmax'][np.random.randint(0, 5)]\n",
    "hparams['lstm_recurrent_activation'] = ['relu', 'sigmoid', 'tanh', 'linear', 'softmax'][np.random.randint(0, 5)]\n",
    "hparams['lstm_dropout'] = 0.05 * np.random.randint(1, 11)\n",
    "hparams['lstm_recurrent_dropout'] = 0.05 * np.random.randint(1, 11)\n",
    "hparams['dense_activation'] = ['relu', 'sigmoid', 'tanh', 'linear', 'softmax'][np.random.randint(0, 5)]\n",
    "hparams['batch_size'] = 2 ** (np.random.randint(3, 11))\n",
    "hparams['learning_rate'] = 10 ** (-np.random.randint(2, 5))\n",
    "hparams['adam_beta_1'] = 0.05 * (np.random.randint(14, 25))\n",
    "hparams['adam_beta_2'] = 0.05 * (np.random.randint(14, 25)) - 0.001\n",
    "hparams['adam_epsilon'] = 10 ** (-np.random.randint(6, 11))\n",
    "hparams['run_id'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 40)\n",
      "(80, 23091)\n",
      "(20, 40)\n",
      "(20, 23091)\n"
     ]
    }
   ],
   "source": [
    "data_x, data_y = load_processed_sparse()\n",
    "data_y = data_y.toarray()\n",
    "data_x = data_x[:100]\n",
    "data_y = data_y[:100]\n",
    "train_x, test_x, train_y, test_y = data_split(data_x, data_y)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/3\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.0039 - P_at_1: 0.0000e+00 - P_at_3: 0.0000e+00 - P_at_5: 0.0000e+00 - P_at_10: 0.0000e+00 - R_at_10: 0.0000e+00 - R_at_50: 0.0032 - R_at_100: 0.0032 - val_loss: 0.0040 - val_P_at_1: 0.0000e+00 - val_P_at_3: 0.0000e+00 - val_P_at_5: 0.0000e+00 - val_P_at_10: 0.0000e+00 - val_R_at_10: 0.0000e+00 - val_R_at_50: 0.0000e+00 - val_R_at_100: 0.0000e+00\n",
      "Epoch 2/3\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.0039 - P_at_1: 0.0000e+00 - P_at_3: 0.0000e+00 - P_at_5: 0.0000e+00 - P_at_10: 0.0000e+00 - R_at_10: 0.0000e+00 - R_at_50: 0.0032 - R_at_100: 0.0032 - val_loss: 0.0040 - val_P_at_1: 0.0000e+00 - val_P_at_3: 0.0000e+00 - val_P_at_5: 0.0000e+00 - val_P_at_10: 0.0000e+00 - val_R_at_10: 0.0000e+00 - val_R_at_50: 0.0000e+00 - val_R_at_100: 0.0000e+00\n",
      "Epoch 3/3\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 0.0039 - P_at_1: 0.0000e+00 - P_at_3: 0.0000e+00 - P_at_5: 0.0000e+00 - P_at_10: 0.0000e+00 - R_at_10: 0.0000e+00 - R_at_50: 0.0032 - R_at_100: 0.0032 - val_loss: 0.0040 - val_P_at_1: 0.0000e+00 - val_P_at_3: 0.0000e+00 - val_P_at_5: 0.0000e+00 - val_P_at_10: 0.0000e+00 - val_R_at_10: 0.0000e+00 - val_R_at_50: 0.0000e+00 - val_R_at_100: 0.0000e+00\n",
      "20/20 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "train_and_validate(train_x, train_y, test_x, test_y, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2864), started 0:51:57 ago. (Use '!kill 2864' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-96d835a80c42ad4b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-96d835a80c42ad4b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "log_dir = '..\\\\..\\\\logs'\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}